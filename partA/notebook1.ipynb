{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumitrapy/da6401_assignment2/blob/main/partA/notebook1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ebc1a698",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebc1a698",
        "outputId": "a9bc5fab-f6e7-437f-d509-df9e5d25ac75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'project'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/45)\u001b[K\rremote: Counting objects:   4% (2/45)\u001b[K\rremote: Counting objects:   6% (3/45)\u001b[K\rremote: Counting objects:   8% (4/45)\u001b[K\rremote: Counting objects:  11% (5/45)\u001b[K\rremote: Counting objects:  13% (6/45)\u001b[K\rremote: Counting objects:  15% (7/45)\u001b[K\rremote: Counting objects:  17% (8/45)\u001b[K\rremote: Counting objects:  20% (9/45)\u001b[K\rremote: Counting objects:  22% (10/45)\u001b[K\rremote: Counting objects:  24% (11/45)\u001b[K\rremote: Counting objects:  26% (12/45)\u001b[K\rremote: Counting objects:  28% (13/45)\u001b[K\rremote: Counting objects:  31% (14/45)\u001b[K\rremote: Counting objects:  33% (15/45)\u001b[K\rremote: Counting objects:  35% (16/45)\u001b[K\rremote: Counting objects:  37% (17/45)\u001b[K\rremote: Counting objects:  40% (18/45)\u001b[K\rremote: Counting objects:  42% (19/45)\u001b[K\rremote: Counting objects:  44% (20/45)\u001b[K\rremote: Counting objects:  46% (21/45)\u001b[K\rremote: Counting objects:  48% (22/45)\u001b[K\rremote: Counting objects:  51% (23/45)\u001b[K\rremote: Counting objects:  53% (24/45)\u001b[K\rremote: Counting objects:  55% (25/45)\u001b[K\rremote: Counting objects:  57% (26/45)\u001b[K\rremote: Counting objects:  60% (27/45)\u001b[K\rremote: Counting objects:  62% (28/45)\u001b[K\rremote: Counting objects:  64% (29/45)\u001b[K\rremote: Counting objects:  66% (30/45)\u001b[K\rremote: Counting objects:  68% (31/45)\u001b[K\rremote: Counting objects:  71% (32/45)\u001b[K\rremote: Counting objects:  73% (33/45)\u001b[K\rremote: Counting objects:  75% (34/45)\u001b[K\rremote: Counting objects:  77% (35/45)\u001b[K\rremote: Counting objects:  80% (36/45)\u001b[K\rremote: Counting objects:  82% (37/45)\u001b[K\rremote: Counting objects:  84% (38/45)\u001b[K\rremote: Counting objects:  86% (39/45)\u001b[K\rremote: Counting objects:  88% (40/45)\u001b[K\rremote: Counting objects:  91% (41/45)\u001b[K\rremote: Counting objects:  93% (42/45)\u001b[K\rremote: Counting objects:  95% (43/45)\u001b[K\rremote: Counting objects:  97% (44/45)\u001b[K\rremote: Counting objects: 100% (45/45)\u001b[K\rremote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/30)\u001b[K\rremote: Compressing objects:   6% (2/30)\u001b[K\rremote: Compressing objects:  10% (3/30)\u001b[K\rremote: Compressing objects:  13% (4/30)\u001b[K\rremote: Compressing objects:  16% (5/30)\u001b[K\rremote: Compressing objects:  20% (6/30)\u001b[K\rremote: Compressing objects:  23% (7/30)\u001b[K\rremote: Compressing objects:  26% (8/30)\u001b[K\rremote: Compressing objects:  30% (9/30)\u001b[K\rremote: Compressing objects:  33% (10/30)\u001b[K\rremote: Compressing objects:  36% (11/30)\u001b[K\rremote: Compressing objects:  40% (12/30)\u001b[K\rremote: Compressing objects:  43% (13/30)\u001b[K\rremote: Compressing objects:  46% (14/30)\u001b[K\rremote: Compressing objects:  50% (15/30)\u001b[K\rremote: Compressing objects:  53% (16/30)\u001b[K\rremote: Compressing objects:  56% (17/30)\u001b[K\rremote: Compressing objects:  60% (18/30)\u001b[K\rremote: Compressing objects:  63% (19/30)\u001b[K\rremote: Compressing objects:  66% (20/30)\u001b[K\rremote: Compressing objects:  70% (21/30)\u001b[K\rremote: Compressing objects:  73% (22/30)\u001b[K\rremote: Compressing objects:  76% (23/30)\u001b[K\rremote: Compressing objects:  80% (24/30)\u001b[K\rremote: Compressing objects:  83% (25/30)\u001b[K\rremote: Compressing objects:  86% (26/30)\u001b[K\rremote: Compressing objects:  90% (27/30)\u001b[K\rremote: Compressing objects:  93% (28/30)\u001b[K\rremote: Compressing objects:  96% (29/30)\u001b[K\rremote: Compressing objects: 100% (30/30)\u001b[K\rremote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "Receiving objects:   2% (1/45)\rremote: Total 45 (delta 16), reused 36 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects:   4% (2/45)\rReceiving objects:   6% (3/45)\rReceiving objects:   8% (4/45)\rReceiving objects:  11% (5/45)\rReceiving objects:  13% (6/45)\rReceiving objects:  15% (7/45)\rReceiving objects:  17% (8/45)\rReceiving objects:  20% (9/45)\rReceiving objects:  22% (10/45)\rReceiving objects:  24% (11/45)\rReceiving objects:  26% (12/45)\rReceiving objects:  28% (13/45)\rReceiving objects:  31% (14/45)\rReceiving objects:  33% (15/45)\rReceiving objects:  35% (16/45)\rReceiving objects:  37% (17/45)\rReceiving objects:  40% (18/45)\rReceiving objects:  42% (19/45)\rReceiving objects:  44% (20/45)\rReceiving objects:  46% (21/45)\rReceiving objects:  48% (22/45)\rReceiving objects:  51% (23/45)\rReceiving objects:  53% (24/45)\rReceiving objects:  55% (25/45)\rReceiving objects:  57% (26/45)\rReceiving objects:  60% (27/45)\rReceiving objects:  62% (28/45)\rReceiving objects:  64% (29/45)\rReceiving objects:  66% (30/45)\rReceiving objects:  68% (31/45)\rReceiving objects:  71% (32/45)\rReceiving objects:  73% (33/45)\rReceiving objects:  75% (34/45)\rReceiving objects:  77% (35/45)\rReceiving objects:  80% (36/45)\rReceiving objects:  82% (37/45)\rReceiving objects:  84% (38/45)\rReceiving objects:  86% (39/45)\rReceiving objects:  88% (40/45)\rReceiving objects:  91% (41/45)\rReceiving objects:  93% (42/45)\rReceiving objects:  95% (43/45)\rReceiving objects:  97% (44/45)\rReceiving objects: 100% (45/45)\rReceiving objects: 100% (45/45), 25.15 KiB | 12.58 MiB/s, done.\n",
            "Resolving deltas:   0% (0/16)\rResolving deltas:   6% (1/16)\rResolving deltas:  12% (2/16)\rResolving deltas:  18% (3/16)\rResolving deltas:  25% (4/16)\rResolving deltas:  31% (5/16)\rResolving deltas:  37% (6/16)\rResolving deltas:  43% (7/16)\rResolving deltas:  50% (8/16)\rResolving deltas:  56% (9/16)\rResolving deltas:  62% (10/16)\rResolving deltas:  68% (11/16)\rResolving deltas:  75% (12/16)\rResolving deltas:  81% (13/16)\rResolving deltas:  87% (14/16)\rResolving deltas:  93% (15/16)\rResolving deltas: 100% (16/16)\rResolving deltas: 100% (16/16), done.\n",
            "/content/project/project\n",
            "--2025-04-22 09:47:14--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.98.207, 142.251.107.207, 74.125.196.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.98.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3816687935 (3.6G) [application/zip]\n",
            "Saving to: ‘nature_12K.zip’\n",
            "\n",
            "nature_12K.zip      100%[===================>]   3.55G   141MB/s    in 37s     \n",
            "\n",
            "2025-04-22 09:47:51 (98.1 MB/s) - ‘nature_12K.zip’ saved [3816687935/3816687935]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/soumitrapy/da6401_assignment2.git project\n",
        "# %cd project\n",
        "# !wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
        "# !unzip -q nature_12K.zip -d data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3c96c29f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c96c29f",
        "outputId": "befc0982-5745-4359-d3d8-8fcc9409b804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'partA'\n",
            "/home/po/Documents/2nd/dl/a2/partA\n"
          ]
        }
      ],
      "source": [
        "# !git pull\n",
        "%cd partA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9d3e977e",
      "metadata": {
        "id": "9d3e977e"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import yaml\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader, random_split\n",
        "\n",
        "from torchvision import transforms\n",
        "#from torchvision.io import read_image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "759b281a",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1b8b8420",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b8b8420",
        "outputId": "37c440a6-df5d-48bc-bbcf-d1fb8baa68fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'project': 'dla2parta',\n",
              " 'use_wandb': False,\n",
              " 'dataset': {'name': 'CustomDataset',\n",
              "  'path': '../data/inaturalist_12K/',\n",
              "  'img_size': 256,\n",
              "  'class_names': ['Plantae',\n",
              "   'Mammalia',\n",
              "   'Animalia',\n",
              "   'Reptilia',\n",
              "   'Amphibia',\n",
              "   'Aves',\n",
              "   'Fungi',\n",
              "   'Arachnida',\n",
              "   'Mollusca',\n",
              "   'Insecta'],\n",
              "  'batch_size': 5},\n",
              " 'train': {'epochs': 1, 'val_interval': 1},\n",
              " 'model': {'name': 'simplecnn',\n",
              "  'in_channels': 3,\n",
              "  'num_classes': 10,\n",
              "  'num_layers': 5,\n",
              "  'filters': [16, 32, 64, 32, 16],\n",
              "  'kernel_size': 3,\n",
              "  'activation': 'relu',\n",
              "  'dense_neurons': 100}}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import yaml\n",
        "config = yaml.safe_load(open(\"config/smallcnn.yaml\"))\n",
        "\n",
        "config['dataset']['batch_size']=5\n",
        "config['train']['epochs']=1\n",
        "config['use_wandb']=False\n",
        "config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "499ece3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "499ece3a",
        "outputId": "3a3aa6f0-9cf1-4fee-82d3-ba43a08f2073"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "if config.get('use_wandb',False):\n",
        "    wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb0e086",
      "metadata": {
        "id": "6cb0e086"
      },
      "source": [
        "### DataLoader Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1245ca4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1245ca4e",
        "outputId": "5f244dac-50c4-42f6-9eda-d808f19955b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train len: 9999, val len: 2000\n",
            "device = cpu\n"
          ]
        }
      ],
      "source": [
        "from preprocessing import CustomDataset\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "cfg = config['dataset']\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(cfg['img_size']),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(cfg['img_size']),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "splits = ['train', 'val']\n",
        "datasets = {x:CustomDataset(path= cfg['path']+x,\n",
        "                            class_names=cfg['class_names'],\n",
        "                            transform=data_transforms[x])\n",
        "            for x in splits}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(datasets[x],\n",
        "                                              batch_size=cfg['batch_size'],\n",
        "                                              shuffle=True\n",
        "                                              )\n",
        "                for x in splits}\n",
        "\n",
        "class_names = datasets['train'].class_names\n",
        "print(f\"train len: {len(datasets['train'])}, val len: {len(datasets['val'])}\")\n",
        "\n",
        "# We want to be able to train our model on an `accelerator <https://pytorch.org/docs/stable/torch.html#accelerators>`__\n",
        "# such as CUDA, MPS, MTIA, or XPU. If the current accelerator is available, we will use it. Otherwise, we use the CPU.\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device = {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2213598f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2213598f",
        "outputId": "783c9593-aa48-4690-d1e8-5c1ac1ba0845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 256, 256]) torch.Size([5])\n"
          ]
        }
      ],
      "source": [
        "for x, y in dataloaders['train']:\n",
        "    print(x.shape,y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66c688e9",
      "metadata": {},
      "source": [
        "### Sweep Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7d3a7ef",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'method': 'random',\n",
              " 'metric': {'name': 'loss', 'goal': 'minimize'},\n",
              " 'parameters': {'filters': [[16, 32, 64, 32, 16],\n",
              "   [8, 16, 16, 32, 64],\n",
              "   [64, 32, 32, 16, 8]],\n",
              "  'kernel_size': [3, 5, 7],\n",
              "  'dense_neuron': [100, 1000],\n",
              "  'activation': ['relu', 'gelu', 'silu']}}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric': {\n",
        "        'name': 'loss',\n",
        "        'goal': 'minimize'\n",
        "    },\n",
        "    'parameters':{\n",
        "        'filters':[[16,32,64,32,16], [8,16,16,32,64], [64,32,32,16,8]],\n",
        "        'kernel_size': [3,5,7],\n",
        "        'dense_neurons': [100, 1000],\n",
        "        'activation': ['relu', 'gelu', 'silu'],\n",
        "    }\n",
        "}\n",
        "sweep_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35711792",
      "metadata": {},
      "outputs": [],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project = 'dla2partb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd859b38",
      "metadata": {},
      "outputs": [],
      "source": [
        "from model.smallcnn import SmallCNN\n",
        "\n",
        "def wandb_train(cfg=None):\n",
        "    with wandb.init(cfg=cfg):\n",
        "        cfg = wandb.config\n",
        "\n",
        "        loss_fn = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.01)\n",
        "        model = SmallCNN(cfg)\n",
        "        train(model=model, optimizer=optimizer, loss_fn=loss_fn, dataloaders=dataloaders,config=config['train'], model_config=config['model'], scheduler = scheduler, device = device, use_wandb = config['use_wandb'])\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1254d9c0",
      "metadata": {
        "id": "1254d9c0"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5365b7a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5365b7a0",
        "outputId": "46117f23-dcdf-4ba8-c70a-75776b4b4eb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.agent(sweep_id, wandb_train, count=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Eg9RZ1xm75Oz",
      "metadata": {
        "id": "Eg9RZ1xm75Oz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
